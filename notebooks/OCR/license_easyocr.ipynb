{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/mnt/c/Users/Rahul/Desktop/Docs and Essentials/Confidential License/mylicense.jpg'\n",
    "model_path = \"/mnt/c/Users/Rahul/Desktop/trained models/License_model.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /mnt/c/Users/Rahul/Desktop/Docs and Essentials/Confidential License/mylicense.jpg: 352x608 4 citizenship_numbers, 2 contact_numbers, 3 dobs, 2 license_numbers, 1 name, 60.7ms\n",
      "Speed: 2.5ms preprocess, 60.7ms inference, 2.2ms postprocess per image at shape (1, 3, 352, 608)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(model_path)\n",
    "results = model(image_path)\n",
    "image = cv2.imread(image_path)\n",
    "ocr = easyocr.Reader(['ne', 'en'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {\n",
    "    0: 'citizenship_number',\n",
    "    1: 'contact_number',\n",
    "    2: 'dob',\n",
    "    3: 'license_number',\n",
    "    4: 'name'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(class_id):\n",
    "    np.random.seed(class_id)\n",
    "    return tuple(np.random.randint(0, 255, 3).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "output_dir = 'OCR_Outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file_path = os.path.join(output_dir, f'{base_name}_results.txt')\n",
    "\n",
    "collected_texts = {label: [] for label in class_map.values()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_conf_boxes = {}\n",
    "\n",
    "for result in results:\n",
    "    boxes = result.boxes.xyxy\n",
    "    class_ids = result.boxes.cls\n",
    "    confidences = result.boxes.conf\n",
    "\n",
    "    for box, class_id, confidence in zip(boxes, class_ids, confidences):\n",
    "        x1, y1, x2, y2 = map(int, box.tolist())\n",
    "        label = class_map.get(int(class_id), 'Unknown')\n",
    "        \n",
    "        # Update only if this class has not been added yet or a higher confidence is found\n",
    "        if label not in highest_conf_boxes or confidence > highest_conf_boxes[label][1]:\n",
    "            highest_conf_boxes[label] = [(x1, y1, x2, y2), confidence]\n",
    "\n",
    "# Process the highest confidence bounding boxes\n",
    "for label, (box, confidence) in highest_conf_boxes.items():\n",
    "    x1, y1, x2, y2 = box\n",
    "    cropped_img = image[y1:y2, x1:x2]\n",
    "\n",
    "    ocr_result = ocr.readtext(cropped_img)\n",
    "    for detection in ocr_result:\n",
    "        text = detection[1]\n",
    "        collected_texts[label].append(text)\n",
    "    \n",
    "    # Define color and thickness for bounding box and label\n",
    "    color = get_color(int(class_id))\n",
    "    thickness = 4  # Thicker bounding box\n",
    "    font_scale = 1.2  # Larger font size\n",
    "    font_thickness = 2  # Thicker font\n",
    "\n",
    "    # Draw bounding box with increased thickness and color\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, font_thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    for label, texts in collected_texts.items():\n",
    "        combined_text = ' '.join(texts)\n",
    "        if combined_text:\n",
    "            file.write(f\"Class: {label}, Text: {combined_text}\\n\")\n",
    "\n",
    "annotated_image_path = os.path.join(output_dir, f'{base_name}_annotated.jpg')\n",
    "cv2.imwrite(annotated_image_path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docmgmt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
